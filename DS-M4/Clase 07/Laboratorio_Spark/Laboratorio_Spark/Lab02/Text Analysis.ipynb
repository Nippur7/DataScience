{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis\n",
    "In this lab, you will create a classification model that performs sentiment analysis of tweets.\n",
    "### Import Spark SQL and Spark ML Libraries\n",
    "\n",
    "First, import the libraries you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"4098m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Data\n",
    "Now load the tweets data into a DataFrame. This data consists of tweets that have been previously captured and classified as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+-----------------------------------------------------------+\n",
      "|ItemID|Sentiment|SentimentSource|SentimentText                                              |\n",
      "+------+---------+---------------+-----------------------------------------------------------+\n",
      "|1038  |1        |Sentiment140   |that film is fantastic #brilliant                          |\n",
      "|1804  |1        |Sentiment140   |this music is really bad #myband                           |\n",
      "|1693  |0        |Sentiment140   |winter is terrible #thumbs-down                            |\n",
      "|1477  |0        |Sentiment140   |this game is awful #nightmare                              |\n",
      "|45    |1        |Sentiment140   |I love jam #loveit                                         |\n",
      "|246   |0        |Sentiment140   |I dislike skiing #rubbish                                  |\n",
      "|776   |1        |Sentiment140   |I like pop music #toptastic                                |\n",
      "|1666  |1        |Sentiment140   |this game is awful good                                    |\n",
      "|1237  |0        |Sentiment140   |rock music is terrible #worstever                          |\n",
      "|1386  |1        |Sentiment140   |that movie is great #favorite                              |\n",
      "|695   |0        |Sentiment140   |I hate this game #fail                                     |\n",
      "|649   |0        |Sentiment140   |I dislike this game #thumbs-down                           |\n",
      "|1565  |1        |Sentiment140   |that movie is great #thumbs-up                             |\n",
      "|150   |1        |Sentiment140   |I like tea #brilliant                                      |\n",
      "|1500  |1        |Sentiment140   |this game is terrible for fans of the other team #nightmare|\n",
      "|1781  |0        |Sentiment140   |this game is terrible #fail                                |\n",
      "|884   |1        |Sentiment140   |this game is brilliant #loveit                             |\n",
      "|1793  |0        |Sentiment140   |jam is terrible #fail                                      |\n",
      "|1782  |0        |Sentiment140   |coffee is terrible #fail                                   |\n",
      "|921   |0        |Sentiment140   |that movie is awful #hateit                                |\n",
      "+------+---------+---------------+-----------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_csv = spark.read.csv('../data/tweets.csv', inferSchema=True, header=True)\n",
    "tweets_csv.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "The features for the classification model will be derived from the tweet text. The label is the sentiment (1 for positive, 0 for negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+-----+\n",
      "|SentimentText                                              |label|\n",
      "+-----------------------------------------------------------+-----+\n",
      "|that film is fantastic #brilliant                          |1    |\n",
      "|this music is really bad #myband                           |1    |\n",
      "|winter is terrible #thumbs-down                            |0    |\n",
      "|this game is awful #nightmare                              |0    |\n",
      "|I love jam #loveit                                         |1    |\n",
      "|I dislike skiing #rubbish                                  |0    |\n",
      "|I like pop music #toptastic                                |1    |\n",
      "|this game is awful good                                    |1    |\n",
      "|rock music is terrible #worstever                          |0    |\n",
      "|that movie is great #favorite                              |1    |\n",
      "|I hate this game #fail                                     |0    |\n",
      "|I dislike this game #thumbs-down                           |0    |\n",
      "|that movie is great #thumbs-up                             |1    |\n",
      "|I like tea #brilliant                                      |1    |\n",
      "|this game is terrible for fans of the other team #nightmare|1    |\n",
      "|this game is terrible #fail                                |0    |\n",
      "|this game is brilliant #loveit                             |1    |\n",
      "|jam is terrible #fail                                      |0    |\n",
      "|coffee is terrible #fail                                   |0    |\n",
      "|that movie is awful #hateit                                |0    |\n",
      "+-----------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = tweets_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "In common with most classification modeling processes, you'll split the data into a set for training, and a set for testing the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1315  Testing Rows: 617\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print (\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "The pipeline for the model consist of the following stages:\n",
    "- A Tokenizer to split the tweets into individual words.\n",
    "- A StopWordsRemover to remove common words such as \"a\" or \"the\" that have little predictive value.\n",
    "- A HashingTF class to generate numeric vectors from the text values.\n",
    "- A LogisticRegression algorithm to train a binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"MeaningfulWords\")\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer, swr, hashTF, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline as an Estimator\n",
    "The pipeline itself is an estimator, and so it has a **fit** method that you can call to run the pipeline on a specified DataFrame. In this case, you will run the pipeline on the training data to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "piplineModel = pipeline.fit(train)\n",
    "print (\"Pipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline Model\n",
    "The model produced by the pipeline is a transformer that will apply all of the stages in the pipeline to a specified DataFrame and apply the trained model to generate predictions. In this case, you will transform the **test** DataFrame using the pipeline to generate label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------+---------+\n",
      "|SentimentText                         |prediction|trueLabel|\n",
      "+--------------------------------------+----------+---------+\n",
      "|I adore cheese #favorite              |1.0       |1        |\n",
      "|I adore cheese #thumbs-up             |1.0       |1        |\n",
      "|I adore classical music #favorite     |1.0       |1        |\n",
      "|I adore coffee #bestever              |1.0       |1        |\n",
      "|I adore coffee #brilliant             |1.0       |1        |\n",
      "|I adore coffee #favorite              |1.0       |1        |\n",
      "|I adore coffee #toptastic             |1.0       |1        |\n",
      "|I adore jam #brilliant                |1.0       |1        |\n",
      "|I adore jam #favorite                 |1.0       |1        |\n",
      "|I adore jam #loveit                   |1.0       |1        |\n",
      "|I adore pop music #thumbs-up          |1.0       |1        |\n",
      "|I adore rock music #loveit            |1.0       |1        |\n",
      "|I adore rock music #toptastic         |1.0       |1        |\n",
      "|I adore skiing #brilliant             |1.0       |1        |\n",
      "|I adore skiing #thumbs-up             |1.0       |1        |\n",
      "|I adore skiing #toptastic             |1.0       |1        |\n",
      "|I adore summer #bestever              |1.0       |1        |\n",
      "|I adore tea #favorite                 |1.0       |1        |\n",
      "|I adore tea #loveit                   |1.0       |1        |\n",
      "|I adore that film #bestever           |1.0       |1        |\n",
      "|I adore that film #favorite           |1.0       |1        |\n",
      "|I adore that film #thumbs-up          |1.0       |1        |\n",
      "|I adore that movie #brilliant         |1.0       |1        |\n",
      "|I adore that movie #favorite          |1.0       |1        |\n",
      "|I adore that movie #thumbs-up         |1.0       |1        |\n",
      "|I adore the holidays #bestever        |1.0       |1        |\n",
      "|I adore the holidays #loveit          |1.0       |1        |\n",
      "|I adore this band #favorite           |1.0       |1        |\n",
      "|I adore this band #thumbs-up          |1.0       |1        |\n",
      "|I adore this game #loveit             |1.0       |1        |\n",
      "|I adore this game #thumbs-up          |1.0       |1        |\n",
      "|I adore this team #loveit             |1.0       |1        |\n",
      "|I adore this team #toptastic          |1.0       |1        |\n",
      "|I adore winter #thumbs-up             |1.0       |1        |\n",
      "|I adore winter #toptastic             |1.0       |1        |\n",
      "|I dislike cheese #fail                |0.0       |0        |\n",
      "|I dislike classical music #nightmare  |0.0       |0        |\n",
      "|I dislike classical music #rubbish    |0.0       |0        |\n",
      "|I dislike classical music #thumbs-down|0.0       |0        |\n",
      "|I dislike coffee #nightmare           |0.0       |0        |\n",
      "|I dislike pop music #thumbs-down      |0.0       |0        |\n",
      "|I dislike rock music #hateit          |0.0       |0        |\n",
      "|I dislike rock music #nightmare       |0.0       |0        |\n",
      "|I dislike rock music #thumbs-down     |0.0       |0        |\n",
      "|I dislike skiing #fail                |0.0       |0        |\n",
      "|I dislike skiing #hateit              |0.0       |0        |\n",
      "|I dislike summer #nightmare           |0.0       |0        |\n",
      "|I dislike summer #worstever           |0.0       |0        |\n",
      "|I dislike tea #worstever              |0.0       |0        |\n",
      "|I dislike that band #hateit           |0.0       |0        |\n",
      "|I dislike that film #hateit           |0.0       |0        |\n",
      "|I dislike that movie #nightmare       |0.0       |0        |\n",
      "|I dislike that movie #rubbish         |0.0       |0        |\n",
      "|I dislike that movie #thumbs-down     |0.0       |0        |\n",
      "|I dislike that movie #worstever       |0.0       |0        |\n",
      "|I dislike this band #fail             |0.0       |0        |\n",
      "|I dislike this band #nightmare        |0.0       |0        |\n",
      "|I dislike this band #thumbs-down      |0.0       |0        |\n",
      "|I dislike this book #fail             |0.0       |0        |\n",
      "|I dislike this book #hateit           |0.0       |0        |\n",
      "|I dislike this book #nightmare        |0.0       |0        |\n",
      "|I dislike this book #worstever        |0.0       |0        |\n",
      "|I dislike this game #rubbish          |0.0       |0        |\n",
      "|I dislike this team #rubbish          |0.0       |0        |\n",
      "|I dislike winter #rubbish             |0.0       |0        |\n",
      "|I don't like this game                |1.0       |0        |\n",
      "|I hate cheese #fail                   |0.0       |0        |\n",
      "|I hate cheese #rubbish                |0.0       |0        |\n",
      "|I hate cheese #worstever              |0.0       |0        |\n",
      "|I hate classical music #rubbish       |0.0       |0        |\n",
      "|I hate classical music #worstever     |0.0       |0        |\n",
      "|I hate coffee #nightmare              |0.0       |0        |\n",
      "|I hate coffee #thumbs-down            |0.0       |0        |\n",
      "|I hate jam #hateit                    |0.0       |0        |\n",
      "|I hate jam #thumbs-down               |0.0       |0        |\n",
      "|I hate pop music #hateit              |0.0       |0        |\n",
      "|I hate pop music #rubbish             |0.0       |0        |\n",
      "|I hate rock music #hateit             |0.0       |0        |\n",
      "|I hate rock music #nightmare          |0.0       |0        |\n",
      "|I hate rock music #worstever          |0.0       |0        |\n",
      "|I hate skiing #fail                   |0.0       |0        |\n",
      "|I hate skiing #hateit                 |0.0       |0        |\n",
      "|I hate skiing #rubbish                |0.0       |0        |\n",
      "|I hate summer #rubbish                |0.0       |0        |\n",
      "|I hate summer #thumbs-down            |0.0       |0        |\n",
      "|I hate summer #worstever              |0.0       |0        |\n",
      "|I hate tea #nightmare                 |0.0       |0        |\n",
      "|I hate tea #thumbs-down               |0.0       |0        |\n",
      "|I hate that band #nightmare           |0.0       |0        |\n",
      "|I hate that film #fail                |0.0       |0        |\n",
      "|I hate that film #hateit              |0.0       |0        |\n",
      "|I hate that film #nightmare           |0.0       |0        |\n",
      "|I hate that film #rubbish             |0.0       |0        |\n",
      "|I hate that movie #rubbish            |0.0       |0        |\n",
      "|I hate that movie #worstever          |0.0       |0        |\n",
      "|I hate this band #worstever           |0.0       |0        |\n",
      "|I hate this game #nightmare           |0.0       |0        |\n",
      "|I hate this team #nightmare           |0.0       |0        |\n",
      "|I hate winter #fail                   |0.0       |0        |\n",
      "|I hate winter #hateit                 |0.0       |0        |\n",
      "+--------------------------------------+----------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = piplineModel.transform(test)\n",
    "predicted = prediction.select(\"SentimentText\", \"prediction\", \"trueLabel\")\n",
    "predicted.show(100, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Python Text Analysis",
  "notebookId": 3378903555804445
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
