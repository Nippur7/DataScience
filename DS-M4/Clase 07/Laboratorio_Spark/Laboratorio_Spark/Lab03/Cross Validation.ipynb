{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cross Validation\n",
    "\n",
    "In this exercise, you will use cross-validation to optimize parameters for a regression model.\n",
    "\n",
    "### Prepare the Data\n",
    "\n",
    "First, import the libraries you will need and prepare the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"4098m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import Spark SQL and Spark ML libraries\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load the source data\n",
    "flightSchema = StructType([\n",
    "  StructField(\"DayofMonth\", IntegerType(), False),\n",
    "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "  StructField(\"Carrier\", StringType(), False),\n",
    "  StructField(\"OriginAirportID\", StringType(), False),\n",
    "  StructField(\"DestAirportID\", StringType(), False),\n",
    "  StructField(\"DepDelay\", IntegerType(), False),\n",
    "  StructField(\"ArrDelay\", IntegerType(), False),\n",
    "  StructField(\"Late\", IntegerType(), False),\n",
    "])\n",
    "\n",
    "data = spark.read.csv('../data/flights.csv', schema=flightSchema, header=True)\n",
    "data = data.select(\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", col(\"ArrDelay\").alias(\"label\"))\n",
    "\n",
    "# Split the data\n",
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "Now define a pipeline that creates a feature vector and trains a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "monthdayIndexer = StringIndexer(inputCol=\"DayofMonth\", outputCol=\"DayofMonthIdx\")\n",
    "weekdayIndexer = StringIndexer(inputCol=\"DayOfWeek\", outputCol=\"DayOfWeekIdx\")\n",
    "carrierIndexer = StringIndexer(inputCol=\"Carrier\", outputCol=\"CarrierIdx\")\n",
    "originIndexer = StringIndexer(inputCol=\"OriginAirportID\", outputCol=\"OriginAirportIdx\")\n",
    "destIndexer = StringIndexer(inputCol=\"DestAirportID\", outputCol=\"DestAirportIdx\")\n",
    "numVect = VectorAssembler(inputCols = [\"DepDelay\"], outputCol=\"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normNums\")\n",
    "featVect = VectorAssembler(inputCols=[\"DayofMonthIdx\", \"DayOfWeekIdx\", \"CarrierIdx\", \"OriginAirportIdx\", \"DestAirportIdx\", \"normNums\"], outputCol=\"features\")\n",
    "lr = LinearRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[monthdayIndexer, weekdayIndexer, carrierIndexer, originIndexer, destIndexer, numVect, minMax, featVect, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters\n",
    "You can tune parameters to find the best model for your data. To do this you can use the  **CrossValidator** class to evaluate each combination of parameters defined in a **ParameterGrid** against multiple *folds* of the data split into training and validation datasets, in order to find the best performing parameters. Note that this can take a long time to run because every parameter combination is tried multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.01]).addGrid(lr.maxIter, [10, 5]).build()\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, numFolds=2)\n",
    "\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Now you're ready to apply the model to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|            features|         prediction|label|\n",
      "+--------------------+-------------------+-----+\n",
      "|[25.0,2.0,10.0,1....|  91.55098885088486|  113|\n",
      "|[25.0,2.0,10.0,1....| 3.6165388181545097|    2|\n",
      "|[25.0,2.0,10.0,57...| 20.401790414644907|   41|\n",
      "|[25.0,2.0,10.0,11...| 26.869050635914675|   30|\n",
      "|[25.0,2.0,10.0,18...|  66.17353371454708|   39|\n",
      "|[25.0,2.0,10.0,18...| 0.3644886897800603|   -5|\n",
      "|[25.0,2.0,10.0,8....| 101.42098827086744|   76|\n",
      "|[25.0,2.0,10.0,49...|  1.485761962843597|  -12|\n",
      "|[25.0,2.0,10.0,37...|  21.89962448155714|    2|\n",
      "|[25.0,2.0,10.0,37...| 0.2641191755003973|  -12|\n",
      "|[25.0,2.0,10.0,37...|  53.37781153719686|   44|\n",
      "|[25.0,2.0,10.0,37...|  59.88160462995418|   54|\n",
      "|[25.0,2.0,10.0,23...|-1.6392028399633674|   92|\n",
      "|[25.0,2.0,10.0,13...|  79.36240267374882|  107|\n",
      "|[25.0,2.0,10.0,13...| 2.4554371424654775|   -3|\n",
      "|[25.0,2.0,10.0,13...|  2.874900839302768|   37|\n",
      "|[25.0,2.0,10.0,13...|  111.2768743440985|  108|\n",
      "|[25.0,2.0,10.0,13...| 50.330561794063556|   94|\n",
      "|[25.0,2.0,10.0,47...|  87.37921616970533|   71|\n",
      "|[25.0,2.0,10.0,12...|  2.419996758702183|   27|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"label\")\n",
    "predicted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Predicted and Actual Values\n",
    "You can plot the predicted values against the actual values to see how accurately the model has predicted. In a perfect model, the resulting scatter plot should form a perfect diagonal line with each predicted value being identical to the actual value - in practice, some variance is to be expected.\n",
    "Run the cells below to create a temporary table from the **predicted** DataFrame and then retrieve the predicted and actual label values using SQL. You can then display the results as a scatter plot, specifying **-** as the function to show the unaggregated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "predicted.createOrReplaceTempView(\"regressionPredictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|label|         prediction|\n",
      "+-----+-------------------+\n",
      "|  113|  91.55098885088486|\n",
      "|    2| 3.6165388181545097|\n",
      "|   41| 20.401790414644907|\n",
      "|   30| 26.869050635914675|\n",
      "|   39|  66.17353371454708|\n",
      "|   -5| 0.3644886897800603|\n",
      "|   76| 101.42098827086744|\n",
      "|  -12|  1.485761962843597|\n",
      "|    2|  21.89962448155714|\n",
      "|  -12| 0.2641191755003973|\n",
      "|   44|  53.37781153719686|\n",
      "|   54|  59.88160462995418|\n",
      "|   92|-1.6392028399633674|\n",
      "|  107|  79.36240267374882|\n",
      "|   -3| 2.4554371424654775|\n",
      "|   37|  2.874900839302768|\n",
      "|  108|  111.2768743440985|\n",
      "|   94| 50.330561794063556|\n",
      "|   71|  87.37921616970533|\n",
      "|   27|  2.419996758702183|\n",
      "+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT label, prediction FROM regressionPredictions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Root Mean Square Error (RMSE)\n",
    "There are a number of metrics used to measure the variance between predicted and actual values. Of these, the root mean square error (RMSE) is a commonly used value that is measured in the same units as the prediced and actual values - so in this case, the RMSE indicates the average number of minutes between predicted and actual flight delay values. You can use the **RegressionEvaluator** class to retrieve the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 17.342191805203203\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(prediction)\n",
    "print (\"Root Mean Square Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Python Cross Validation",
  "notebookId": 374219277805981
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
